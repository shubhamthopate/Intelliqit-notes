Day 1

====================
Docker
===================

Virtualization
===================
	Here we a have a baremetal (H/W) on which we install the 
host OS and on the host OS we install an application  called as
hypervisor,on this hypervisor we can install guest OS and on the
guest OS we can run the s/w applications that we want
This technology enables us to run multiple OS's parallely on one
server.
The disdavantage is these applications have to pass through so many 
layers in order to access the H/W resources.
Similary each VM requires fixed amout of H/W to be allocated


Containarization
==========================
	Here we have a bare metal on top of which we install the host
OS and on the host OS we install an application called as Docker Engine
On this docker  engine we can run any application in the form of container
These containers are extrememly light weight and consume very less amount
of H/W resources.They can be created very quickly comared to VM's

Docker is used for "process isolation" ie the depndency that an application 
has on an OS is removed and they can directly run on top of docker engine.
The advantage is we nedd not spend money on licensing of the OS's
Docker can be used at all the below stages of s/w development
Build--->Ship--->Run

=======================================================================
Day 2
========================================================================
Installing docker on Windows
======================================
1 Open https://docs.docker.com/docker-for-windows/install/
2 Download docker fow windows---->Install it
3 To execute docker command use "PowerShell"

Note: Docker can be installed on on Windows 10 Prof 64 bit version 
or Windows 2016 Server edition

Note: Once docker is installed on Windows it activates an application
called Windows hypervisor(HyperV).Once this is activated it will not allow
any other virtualization s/w to run


=======================================================================
Setup of Ubuntu Server using vagrant
---------------------------------------
Vagrant
===================
1 Download and install Oracle virtual Box
  https://www.virtualbox.org/wiki/Downloads

2 Download and install vagrant
  https://www.vagrantup.com/downloads.html

3 To check if vagrant is installed
  vagrant --version

4 Copy the vagrantfile into an empty folder

5 Open cmd prompt
  cd path_of_folder_where_vagrantfile_is_copied
  vagrant up

6 Open Oracle virtual box to access these VM's
  Username and Password: vagrant

7 To install docker
  a)Download the shell script for docker
    curl -fsSL https://get.docker.com -o get-docker.sh
  b)Execute the shell script
    sh get-docker.sh


======================================================================
Setup of docker on a linux machine on AWS
=========================================
1 Create an AWS ubuntu20 instance
2 Connect to it using git bash
3 Download the shell script for docker
  curl -fsSL https://get.docker.com -o get-docker.sh
4 Install docker
  sh get-docker.sh


Url: http://get.docker.com

=========================================================================
Day 3
=========================================================================
Important Docker commands
===================================

Working on Images
-----------------------
1 To download a docker image
  docker pull image_name

2 To see the list of dokcer images present in our docker host
  docker image ls
  or
  docker images

3 To search for an image on the registry
  docker search image_name

4 To delete an image
  docker rmi image_name/image_id

5 To get detailed info about a image
  docker image inspect image_name/image_id

6 To create an image from a container
  docker commit contianer_name/container_id image_name

7 To create an image from a dockerfile
  docker build -t image_name .

8 To delete all images
  docker system prune -af

9 To save an image as a tar file
  docker image save image_name/image_id

10 To untar the above tar file and get an image
   docker image load tar_file_name

11 To push docker images
   docker push image_name

==============================================================================
Working on docker containers
===============================
12 To create a docker container from an image
   docker run image_name
   Options used in run command
   --name: This is used to assign a name to the container
   -it: Used to open interactive terminal in the container
   -d : Used to run the container in detached mode(backgroud)
   -e : Used to pass environment variables to container
   -v : Used to attach volumes to a docker container
   --volumes-from: Used to share volumes between containers
   -p : Used for port mapping.It will link the container port(internal port)
        with the host port(external port)
        Eg: -p 8080:80 Here 8080 is host port and 80 is container port
   -P : Used for automatic port mapping ie it will link the container port
        with a host port that is greater than 30000 
   --link : Used to setup a multi container architecture
   --network: Used to run a container on a specific custom network
   -rm : Used to delete a container on exit
   -m : Used to specify the maximum amount of memory that a container can use
  -c: Used to specify the maximum percentage of cpu that a container can use
  -ip: Used to assign an ip to a container


============================================================================
Day 4
============================================================================
13 To see the list of running containers
   docker container ls

14 To see the list of running and stopped containers
   docker ps -a

15 To stop a running container
   docker stop container_name/container_id

16 To start the stopped container
   docker start container_name/container_id

17 To restart a runnng container
   docker restart container_name/container_id
   To restart a container after 20 seconds
   docker restart -t 20 container_name/container_id

18 To delete a stopped container
   docker rm container_name/container_id

19 To delete a running container
   docker rm -f container_name/container_id

20 To stop all running containers
   docker stop $(docker ps -aq)

21 To delete all stopped containers
   docker rm $(docker ps -aq)

22 To delete all running and stopped containers
   docker rm -f $(docker ps -aq)

23 To see the logs generated by container
   docker logs container_name/container_id

24 To see the ports opened by a container
   docker port container_name/container_id

25 To come out of a container without exit
   ctrl+p,ctlr+q

26 To go back into a container that we come out without exit
   docker attach container_name/container_id

27 To run a command or process in a container from out side the container
   docker exec -it container_name/container_id command_to_run
   Eg: To open the bash process in a container
   docker exec -it container_name/container_id bash

28 To see the list of process running in a container
   docker top container_name/container_id

29 To get detailed info about a container
   docker inspect container_name/container_id

===========================================================================
Working on docker networks
----------------------------------
30 To see the list of docker networks
   docker network ls

31 To create a docker network
   docker network create --driver network_type network_name 

32 To delete a network
   docker network rm network_name/network_id

33 To connect a running container to a network
   docker network connect network_name/network_id container_name/container_id

34 To remove a running container from a network
   docker network disconnect network_name/network_id container_name/container_id

35 To get detailed info about a network
   docker network inspect network_name/network_id 

=======================================================================
Working on docker volumes
-----------------------------
36 To see the list of docker volumes
   docker volume ls

37 To create a docker volume
   docker volume create volume_name

38 To get detailed info about a volume
   docker volume inspect volume_name/volume_id

39 To delete a docker volume
   docker volume rm volume_name/volume_id

=====================================================================
Day 5
=====================================================================
UseCase 1
=============
Create an nginx contaienr in detached mode and name it webserver
Also perfrom port mapping

docker run  --name webserver -p 8888:80 -d nginx

To check if the nginx container is running
docker container ls

To access the nginx container from the leve of browser
public_ip_of_dockerhost:8888

============================================================================
UseCase 2
===============
Start a jenkins container in detached mode and also perfrom port mapping
docker run --name myjenkins -d -p 9999:8080 jenkins

To check if jenkins container is running
docker container ls

To access jenkins from browser
public_ip_of_docker_host:9999
===================================================================================
UseCase 3
================
Start htppd as a container and perfrom automatic port mapping
docker run --name appserver -d -P httpd

To see the ports used by the above container
docker port appserver

To access the httpd from borwser
piblic_ip_of_dockerhost:port_captured_from_above_command

=================================================================================
UseCase 4
==================
Start centos as a container and launch interactive terminal in it
docker run --name mycentos -it  centos

To come out of the centos container
exit

====================================================================================
UseCase 5
===================
Create a mysql container and login as root user and create some sql tables

1 Create a mysql container
  docker run --name db -d -e MYSQL_ROOT_PASSWORD=intelliqit mysql:5

2 To check if the mysql container is running
  docker container ls

3 To go into the bash shell of the container
  docker exec -it db bash

4 To login into the database
  mysql -u root -p
  Password: intelliqit

5 To see the list of databases
  show databases;

6 To move into any of the above database
  use databasename;
  Eg: use sys;

7 To create emp and dept tables here
  Open
  https://justinsomnia.org/2009/04/the-emp-and-dept-tables-for-mysql/
  Copy script from emp and dept tables creation
  Paste in the mysql container

8 To see the data of the tables
  select * from emp;
  select * from dept;


====================================================================
Day 6
====================================================================
Creating a multi container architecture(microservices architecture)
=====================================================================
Various types of development and testing environments can be
created using docker in the following ways

1  --link  option (depricated)
2  docker-compose
3 Docker networking

4 Python Scripts
5 Ansible

--link Option: This is a docker run command option and it is
depricated.

UseCase 1
=============
Create 2 busybox containers and link them

1 Create a busybox container
  docke run  --name c1 -it busybox

2 To come out of the container without exit
  ctrl+p,ctrl+q

3 Create another busybox container and link it with the c1 container
  docker run  --name c1 --link c1:mybusybox -it busybox

4 Check if c2 can ping to c1
  ping c1


UseCase 2
=====================
Create a mysql container and a wordpress container and
link them

1 Create mysql:5 as a container
  docker run  --name db -d -e MYSQL_ROOT_PASSWORD=intelliqit mysql:5

2 Create a wordpress container and link it with a mysql container
  docker run --name mywordpress -d -p 8888:80 --link db:mysql wordpress

3 To check if wordpress is linked with mysql container
  docker inspect mywordpress
  Search for "Links" section

4 To acces the wordpress from browser
  public_ip_of_dockerhost:8888

UseCase 3
================
Create a jenkins container and link with 2 tomcat containers
one for QAserver and another for prodserver

1 Create a jenkins container
  docker run  --name jenkins -d -p 5050:8080 jenkins

2 To access jenkins from browser
  public_ip_of_dockerhost:5050

3 Create a tomcat container as qaserver and link with jenkins
  docker run --name qaserver -d -p 6060:8080 --link jenkins:myjenkins tomcat

4 Create another tomcat container as prodserver and link with jenkins
  docker run --name prodserver -d -p 7070:8080 --link jenkins:myjenkins tomcat

======================================================================
Use Case 4
================
Setup a postgres db and link with adminer container to access db from browser

1 Create a postgres db container
  docker run --name db -d -e POSTGRES_DB=intelliqit -e POSTGRES_USER=myuser
                                                 -e POSTGRES_DB=mydb postgres

2 Create an adminer container and link witj postgres 
  docker run --name myadminer -d -p 9999:80 --link db:postgres adminer

3 To access from level of browser
  public_ip_of_dockerhost:9999
==============================================================================

UseCase 5
===========
Setup LAMP architecture where a mysql container can be linked
with an apache and php container

1 Create a mysql container
  docker run --name db -d -e MYSQL_ROOT_PASSWORD=intelliqit mysql

2 Create an apache and link with mysql container
  docker run --name apache -d -p 9090:80 --link db:mysql  httpd


3 Create a php container and link with apache and mysql containers
  docker run --name php -d --link db:mysql --link apache:httpd php:7.2-apache

4 To check if php container is linked with mysql and apache container
  docker inspect php
  Search for "Links" section

==============================================================================
Day 7
==============================================================================
UseCase-1
=================
Create a testing environment where a selenium hub container
should be linked with 2 node containers one with chrome
installed and other with firefox installed.The testers should be 
able to run the cross browser,cross platform automation
test scripts

1 Create a selenium hub image
  docker run --name hub -d -p 4444:4444 selenium/hub

2 Create a chrome node and link with the hub container
   docker run --name chrome -d -p 5901:5900 --link hub:selenium  
                                           selenium/node-chrome-debug

3 Create a firefox node and link with the hub container
  docker run --name firefox -d -p 5902:5900 --link hub:selenium 
                                           selenium/node-firefox-debug

4 Check if all 3 containers are running
  docker container ls

5 The above 2 containers are GUI containers and to access the GUI of
  these containers
  a) Install VNC viewer from https://www.realvnc.com/en/connect/download/viewer/
  b) Open vnc viewer
  c) public_ip_of_dockerhost:5901 and 5902
  d) Click on continue--->Enter password:secret


===========================================================================
Docker compose
================
This is another way of creating a mult container architecture.This uses yaml files.The main advantage of docker compose is reusability.

Installing docker compose
=============================
1 Download docker compose
  sudo curl -L "https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose

2 Give execute permissions
  sudo chmod +x /usr/local/bin/docker-compose

3 To check the verion of docker compose
  docker-compose --version

URL:https://docs.docker.com/compose/install/

==============================================================================
Create a docker compose file to setup of mysql and wordpress containers

1 vim docker-compose.yml
---
version: '3.8'

services:
 db:
  image: "mysql:5"
  environment:
   MYSQL_ROOT_PASSWORD: intelliqit

 mywordpress:
  image: wordpress
  ports:
   - "8888:80"
  links:
   - "db:mysql"
...

2 To create the services from above file
  docker-compose up -d

3 To see the list of containers
  docker container ls

4 To stop the containers
  docker-compose stop

5 To delete the containers
  docker-compose down


==================================================================
Day 8
===================================================================
Create a docker compose file to setup of postgres and adminer containers

1 vim docker-compose.yml
---
version: '3.8'

services:
 db:
  image: postgres
  environment:
   POSTGRES_PASSWORD: intelliqit
   POSTGRES_USER: myuser
   POSTGRES_DB: mydb

 adminer:
  image: adminer
  ports:
   - 8888:8080
  links:
   - db:postgres
...

2 To create the services from above file
  docker-compose up -d

3 To see the list of containers
  docker container ls

4 To stop the containers
  docker-compose stop

5 To delete the containers
  docker-compose down

==============================================================================
Create a docker compose file to setup CI-CD environment where
a Jenkins container is linked with 2 tomcat containers

1 vim abc.yml
---
version: '3.8'

services:
 jenkins:
  image: jenkins
  ports:
   - 5050:8080

 qaserver:
  image: tomcat
  ports:
   - 6060:8080
  links:
   - jenkins:myjenkins

 prodserver:
  image: tomcat
  ports:
   - 7070:8080
  links:
   - jenkins:myjenkins
...

2 To setup the services from the above file
  docker-compose -f abc.yml up -d



=========================================================================
Day 9
=========================================================================
Create a docker compose file to setup the selenium testing environment
vim docker-compose.yml
---
version: '3.8'

services:
 hub:
  image: selenium/hub
  ports:
   - 4444:4444

 chrome:
  image: selenium/node-chrome-debug
  ports:
   - 5901:5900
  links:
   - hub:selenium

 firefox:
  image: selenium/node-firefox-debug
  ports:
   - 5902:5900
  links:
   - hub:selenium
...

===========================================================================
==========================================================================
Docker Volumes
=====================
Docker Containers are ephemiral ie temporary but the data processed
by the container should be persistent
To handle this we can use docker volumes,These are used for preserving the 
data even after the container is deleted

Volumes are of 3 types
1 Simple docker volumes
2 Sharable Volumes
3 Docker volume containers

========================================================
========================================================

Simple docker volume
----------------------
This is used only for preserving the data even though the 
container is deleted

UseCase
-----------
Create a directory /data on the host machine
Create an ubuntu container and mount this /data
as a volume on this contianer.Create some files in this mounted
volume and check if the files are still available on the host
machine even when the container is deleted

1 Create a directory /data
  mkdir /data

2 Create an ubuntu container and mount /data as a volume
  docker run --name u1 -it -v /data ubuntu

3 In the ubuntu u1 container go into data folder(mounted volume)
  and create some files
  cd data
  touch file1 file2
  exit

4 Indentify the mounted locations
  docker inspect u1
  Go to "Mounts" sections and copy the "Source" path
  
5 Delete the container
  docker rm -f u1

6 Check if the data is still present on host machine
  cd "Source_path_from_step4"
  ls

Sharables Volumes
=======================
These volumes can be shared betwen multiple containers
and the changes done by one container will be reflected
to all other containers

UseCase
===========
Create a folder /data on the dockerhost.mount it as a volume on
centos container c1,later create another centos container c2
and this c2 should use the volume used by c1,create another
centos container c3 and this should use the volume used by c2
Delete all three containers and check if the data is still present 
on the host machine

1 Create /data folder
  mkdir /data

2 Start centos as a container and mount /data as a volume 
  docker run --name c1 -it -v /data centos

3 In the centos c1 container go into the volume and create files
  cd data
  touch file1 file2
  Come out of the container without exit (ctrl+p,ctrl+q)

4 Create another centos container c2 and this container should use
  the volume used by c1
  docker run --name c2 -it --volumes-from c1 centos

5 In the centos c2 container go into the volume and create files
  cd data
  touch file3 file4
  Come out of the container without exit (ctrl+p,ctrl+q)

6 Create another centos container c3 and this container should use
  the volume used by c2
  docker run --name c3 -it --volumes-from c2 centos

7 In the centos c3 container go into the volume and create files
  cd data
  touch file5 file6
  Come out of the container without exit (ctrl+p,ctrl+q)

8 Go into any of the 3 containers and we should see all the files
  docker attach c1 (or) c2 (or) c3
  ls
  exit

9 Identify the mounted location
  docker inspect c1
  Go to "Mounts" section and copy the "Source" path

10 Delete all the 3 containers
   docker rm -f c1 c2 c3

11 Check if the files are still available on the host machine
   cd "source path coped from step 9"
   ls

=========================================================================
Docker volume containers
==============================
These are by directional volumes ie the files from the
host can be accessed in the container and the files from the
container can be accesed on the host

UseCase
----------------
Create a volume "myvolume",Create some files in this volume
and attach it to a centos container.In the centos container
check if this data is available.Similary create some files
in the volume in the container and check if these files are
available on the host

1 Create a docker volume
  docker volume create myvolume

2 Identify the volume location
  docker volume inspect myvolume
  Copy the MountPoint path

3 Go to this mountpoint and create some files
  cd MountPoint+path_from_step2
  touch file1

4 Create a centos container and mount the volume on /tmp folder in the container
  docker run  --name c1 -it -v myvolume:/tmp centos

5 Go into the tmp folder in the container and check if the files from host
  are available
  cd tmp
  ls
  
6  Create few files
   touch file2 file3
   exit

7 Delete the centos container
  docker rm -f c1

8 Check if the data is still present
  cd MountPoint_path_from_step2
  ls

===============================================================================
Day 10
===============================================================================
=========================================================================
UseCase 1
===============
Create a volume called "newvolume" and store tomcat-users.xml file
Mount this volume into a tomcat container

1 Create a volume
  docker volume create newvolume

2 Identify the Mount location of the volume
  docker volume inspect newvolume

3 Go to the Mount point location
  cd path_of_Mount_point_from_step2

4 Create tomcat-users.xml file
  vim tomcat-user.xml
  <tomcat-users>
     <user username="intelliqit" password="intelliqit" roles="manager-script"/>
  </tomcat-users>

5 Create a tomcat container and mount the above volume
  docker run --name t1 -d -P -v newvolume:/tmp tomcat

6 Go into the shell of the above tomcat container
  docker exec -it t1 bash

7 Check if the tomcat-users.xml file is present in /tmp folder
  cd/tmp
  ls

=======================================================================
Creating customied docker images
======================================
This can be done in 2 ways 
1 Using the docker commit command
2 Using the docker file

Using docker commit command
===================================
UseCase
==========
Create a customsied docker ubuntu image where git and maven are installed

1 Create a ubuntu container
  docker run --name u1 -it ubuntu

2 In this ubuntu container update apt and install git and maven
  apt-get update
  apt-get install -y git 
  apt-get install -y maven
  exit

3 Save the container  u1 as an image
  docker commit u1 myubuntu

4 Delete the ubuntu u1 container
  docker rm -f u1

5 Check if the new image is created
  docker images

6 Create a container from the above created image and check if git and maven
  are already present
  docker run --name u1 -it myubuntu
  git --verion
  mvn --version


======================================================================
Dockerfile
=================
This is used for creating customised docker images
Dockerfile is a simple text file which uses certain predefined
keywords for perfoming various activites related to image creation.

Important keywords used in Dockerfile
========================================
FROM: This is used to specify the base image from which we should
      create the customised docker image

MAINTAINER: Used to represent the name of the author or the organization
	    that is creating this dockerfile

RUN: This is used to run linux commands in the image,generally it is used
     for upgrading s/w packages and installing s/w applications in the image

CMD: This is used to run an application in the container even when the
     control is outside the container

ENTRYPOINT: Every docker container triggers a specific process when it
            starts and this is the known as the "default process"
            of the container and the the container will be running condition
            only as long as this default process runs,We can specify 
            what should be the default process if a container using this
            option

VOLUME :  Used to attach or mount a deafult volume to a container

EXPOSE: This is used to expose a container port so that it can  be mapped
         with a host port


COPY:  Used to copy files from host to container

ADD: Used to copy files from host to container but it can also download
     files from remote servers into the container

USER: This is used to specify the default user who should login into the
      container

WORKDIR: Used to specify the default directory where the command should be
         executed in a container

SHELL: USed to specify what shell should run in the container Eg: bash,sh,ksh

LABEL:  Used to give a default label to container

STOPSIGNAL:  USed to specify the key sequence that has to be passes to
             stop the container


====================================================
Create a dockerfile from nginx base image and specify the 
maintainer as intelliqit

1 vim dockerfile
FROM nginx
MAINTAINER intelliqit

2 To build an image from the above dockerfile
  docker build -t mynginx .

3 Check if a new image called mynginx is created
  docker images

====================================================
Create a dockerfile from centos base image and install git in it

1 vim dockerfile

FROM centos
MAINTAINER intelliqit
RUN yum -y update
RUN yum install -y git

2 To build an image from the above dockerfile
  docker build -t mycentos .

3 Check if a new image called mycentos is created
  docker images

4 Create a container from the above image and check if git is installed
  docker run --name c1 -it mycentos
  git --version




==================================================================
Cache Busting
===================
Whenever we create an image from a dockerfile docker stores all
the executed instructions in the "dockercache",next time if we
make modifications to the dockerfile and rebuild a new image
docker reads all the previously executed instructions from the '
dockercache and it will execute only the new instructions
This is a time saving machanism provided by docker

Eg:
FROM ubuntu
RUN apt-get update
RUN apt-get install -y git

If we create an image from the above dockerfile it save all these instructions
in the dockecache and alter if we add the below statement
RUN apt-get install -y tree
and if we build an image from this docker file it will execute on the 
latest instruction

The disadvantage is if we edit the docker file after a huge timegap
then we can end up installing s/w from a reposiotry that was updated 
log time back

To overcome this we can use "cache busting" ie we can tell docker
to build an image from the dockerfile without reading previosuly
executed instructions from the dockercache

docker build --no-cache -t myubuntu .


==============================================================================
Day 11
===============================================================================
Create a dockerfile that create an ubuntu image with ansible installed on it

1 vim dockerfile
FROM ubuntu
MAINTAINER intelliqit
RUN apt-get update
RUN apt-get install -y ansible

2 Create an image from the above dockerfile
  docker build -t ansible .

3 Create a container from the above image and check if ansible is present
  docker run --name u1 -it myubuntu
  ansible --version

============================================================================ 
Create a dockerfile from ubuntu base image and mount /data
as the default volume

1 vim dockerfile
FROM ubuntu
MAINTAINER intelliqit
VOLUME /data

2 Create an image from the above dockerfile
  docker build -t myubuntu .

3 Create a container from the above image
  docker run --name u1 -it myubuntu

4 Go into the mounted volume and create few file
  cd data
  touch file1 file2
  exit

5 Check the mounted location
  docker inspect u1
  Go to "Mounts" section and copy the "Source" path

6 Delete the container
  docker rm -f u1

7 Check if the data is still present on the host machine
  cd "Source_path_from_step5"
  ls


===================================================================
Create a dockerfile from nginx base image and expose 90 as
the container port

1 vim dockerfile
FROM nginx
MAINTAINER intelliqit
EXPOSE 90

2 To build an image from the above dockerfile
  docker build -t mynginx .

3 Create a container from the above image
  docker run --name n1 -d -P mynginx

4 Check the port of the container
  docker port n1


==============================================================================
Create a dockerfile from jenkins base image and make the deafult user
as root and also install git amd maven

1 vim dockerfile

FROM jenkins
MAINTAINER intelliqit
USER root
RUN apt-get update
RUN apt-get install -y git maven

2 Create an image from the above file
  docker build -t myjenkins .

3 Create a container from the above image
  docker run --name j1 -d -P myjenkins

4 Go into the bash shell of the container and check who is the 
  default user and also check if the git and maven are present
  docker exec -it j1 bash
  whoami
  git --version
  mvn --version

=============================================================================

Create a dockerfile from ubuntu base image and download
jenkins.war into it

1 vim dockerfile
  FROM ubuntu
  MAINTAINER intelliqit
  ADD  http://mirrors.jenkins.io/war-stable/2.235.3/jenkins.war  /

2 Build an image from the above dockerfile
  docker build -t myubuntu .

3 Create a container from the above image and we should see jenkins.war in it
  docker run  --name u1 -it myubuntu
  ls
=============================================================================
Day 12
============================================================================
=============================================================================
Create a dockerfile from centos base image and install
httpd in it.Copy index.html into this and make httpd as the
default process of the container

1 vim index.html
<html>
 <body>
         <h1>Welcome to IntelliQIt</h1>
  </body>
</html>

2 vim dockerfile
FROM centos
MAINTAINER intelliqit
RUN yum -y update
RUN yum install -y httpd 
COPY index.html /var/www/html
ENTRYPOINT ["/usr/sbin/httpd","-D","FOREGROUND"]
EXPOSE 80

3 Create an image from the above file
  docker build -t mycentos .

4 Create a container from the above image
  docker run --name c1 -d -P mycentos

5 Check if we can access this container from browser
  public_ip_dockerhost:port_no_from_step4


========================================================================
Create a dockerfile from ubuntu image and make it behave
like an nginx container

1 vim dockerfile
FROM ubuntu
MAINTAINER intelliqit
RUN apt-get update
RUN apt-get install -y nginx
ENTRYPOINT ["/usr/sbin/nginx","-g","daemon off;"]
EXPOSE 80

2 Create an image from the above dockerfile
  docker build -t myubuntu .

3 Create a container a from the above image
  docker run --name c1 -d -P myubuntu

4 to access the nginx from browser
  public_ip_dockerhost:port_no_from_step3


========================================================================

Docker Networking
=====================
Docker uses 4 types os networks
1 Bridge: This is the deafult network of docker when contianers are
          running on a single docker host

2 Host: This is used when we want to run a single container on a dockerhost
         and this contianer communicates only with the host machine

3 Null: This is used for creating isolated containers ie these containers
        cannot communicate with th host machine or with other containers

4 Overlay: This is used when containers are running in a distributed environment
           on multiple linux servers

===========================================================================
Day 13
===========================================================================

UseCase
===============
Create 2 bridge networks intelliq1 and intelliq2
Create 2 busybox containers c1,c2 and c3
c1 and c2 should run on intelliq1 network and shoul ping each other
c3 should run on intelliq2 network and it should not be able to ping c1 or c2
Now put c2 on intelliq2 network,since c2 is on both intelliq1 and intelliq2
networks it should be able to ping to both c1 and c3
but c1 and c3 should not ping each other directly

1 Create 2 bridge networks
  docker network create --driver bridge intelliq1
  docker network create --driver bridge intelliq2

2 Check the list of available networks
  docker network ls

3 Create a busybox container c1 on intelliqi1 network
  docker run --name c1 -it --network intelliq1 busybox
  Come out of the c1 container without exit ctrl+p,ctrl+q

4 Identify the ipaddress of c1
  docker inspect c1

5 Create another busybox container c2 on intelliq1 network
  docker run --name c2 -it --network intelliq1 busybox
  ping ipaddress_of_c1    (It will ping)
  Come out of the c2 container without exit ctrl+p,ctrl+q

6 Identify the ipaddress of c2
  docker inspect c2

7 Create another busybox container c3 on intelliq2 network
  docker run --name c3 -it --network intelliq2 busybox
  ping ipaddress_of_c1  (It should not ping)
  ping ipaddress_of_c2  (It should not ping)
  Come out of the c3 container without exit ctrl+p,ctrl+q

8 Identify the ipaddress of c3
  docker inspect c3 

9 Now attach intelliq2 network to c2 container
  docker network connect intelliq2 c2

10 Since c2 is now on both intelliq1 and intelliq2 networks it should ping
   to both c1 and c3 containers
   docker attach c2
   ping ipaddress_of_c1  (It should  ping)
   ping ipaddress_of_c3  (It should  ping)
   Come out of the c2 container without exit ctrl+p,ctrl+q

11 But c1 and c3 should not ping each other
   docker attach c3
   ping ipaddress_of_c1  (It should not ping)


Note: To create network with a specific subnet range
docker network create --driver bridge --subnet=192.168.2.0/24 intelliqit3

=============================================================================
========================================================================

Create docker compose file to start a postgres db and adminer
webapplication on the network that we created

1 Create a new network
  docker network create --driver bridge --subnet=192.168.2.0/24 new_intelliqit

2 Create a dcoker compose file
vim docker-compose.yml
---
version: '3.8'

services:
 db:
  image: postgres
  environment:
   POSTGRES_PASSWORD: intelliqit
   POSTGRES_USER: user1
   POSTGRES_DB: mydb

 adminer:
  image: adminer
  ports:
   - 8888:8080

networks:
 default:
  external:
   name: new_intelliqit

3 To create services from the above dockerfile
  docker compose up -d

4 Check if the adminer can access the db from browser
  public_ip_of_dockerhost:8888

5 Check the ipaddress of the containers 
  docker container ls
  docker insepct container_id_from_above_command

============================================================================
UseCase
Create a docker compsoe file to start one jenkins and 2 tomcat contianers
jenkins container should run on abc network and tomcats shoudl run on xyz network

vim docker-compose.yml
---
version: '3.8'

services:
 jenkins:
  image: jenkins
  ports:
   - 5050:8080
  networks:
   - abc

 qaserver:
  image: tomcat
  ports:
   - 6060:8080
  networks:
   - xyz

 prodserver:
  image: tomcat
  ports:
   - 7070:8080
  networks:
   - xyz

networks:
 abc: {}
 xyz: {}

=====================================================================
UseCase
Create a docker compose file to link mysql and wordpress
containers also this file should create 2 volumes one for
each container and it should create 2 bridge networks
one for each container

vim docker-compose.yml
---
version: '3.8'

services:
 db:
  image: mysql:5
  environment:
   MYSQL_ROOT_PASSWORD: intelliqit
  volumes:
   - db:/var/lib/mysql
  networks:
   - mywordpress_app

 wordpress:
  image: wordpress
  ports:
   - 8989:80
  volumes:
   - wordpress:/var/www/html
  networks:
   - mywordpress_app

volumes:
 wordpress:
 db:

networks:
 mywordpress_app: {}
 


2 To create container from the above docker file
  docker-compose up -d

3 Check if one network mywordpress_app is created
  docker network ls

4 Check if 2 volumes  db and wordpress are created
  docker volume ls

===========================================================================
Day 14
============================================================================
Create a docker compose file that uses a docker file to build an image
and also a tomcat container

vim dockerfile
FROM ubuntu
MAINTIANER intelliqit
RUN apt-get update
RUN apt-get install -y git

vim docker-compose.yml
version: '3'

services:
 myubuntu:
  build: .
  
 mytomcat:
  image: tomcat

To setup the architecture
docker-compose up -d

======================================================================
Working on registry
================================
Registry is the location where the docker images can be stored
This is of 2 types
Public registry
Private Registry

Public Registry is hub.docker.com and images uplaoded here can be access by
anyone

UseCase
------------
Create a customised ubuntu image and upload into dockerhub

1 Open hub.docker.com
2 Signup for a free account
3 Create a customised ubuntu image
  a) Start ubuntu as a container
     docker run  --name u1 -it ubuntu
  b) Install somw s/w's in it
     apt-get update
     apt-get install -y wget git vim
     exit
4 Save this container as an image
  docker commit u1 intelliqit/ubuntu_123

5 Login into dockerhub
  docker login
  Enter username and apssword of dockerhub

6 Push the image
  docker push intelliqit/ubuntu_123


===========================================================================
======================================================================
Private Registry
======================
This is an a docker image called "registry" and once we start
it as a container it start working like a local registry

1 Create a registry
  docker run --name lr -d -p 5000:5000 registry

2 Download alpine image
  docker pull alpine

3 Tag this image with the local registry
  docker tag alpine localhost:5000/alpine

4 Push it into the local registry
  docker push localhost:5000/alpine

=========================================================================
Day 15
=========================================================================

Container Orchestration
===========================
This is the process of running docker containers in a distributed
environment on multiple linux servers

Advantages
=================
1 Load Balancing: The services can be deployed on multiple containers
running on multiple servers so that the load can be distributed between
containers and servers.On all these containers we can have only one
service running

2 Scalling: Depending on the business requirement we can increase or
decrease the number of containers on which a specific service is running
without the end users experiencing any downtime

3 Rolling update: Services running on docker in a production environment
can be upgraded to a higher version or rolled back to a lower version
without the end users experiencing downtime.This is done by upgrading
one container after other in a rolling manner

4 High Availability/Disaster Recovery: If a container fails or the server
on which these containers are running crashes still we can maintian
the "desired number" of containers on the remaining servers.

Popular tool for container orchestration
===============================================
1 Docker Swarm
2 Kubernetes
3 OpenShift
4 Apache Mesos


Docker Swarm
==============
This is a contianer orchestration tool of docker and it helps us to
managed docker containers running on multiple servers

The main machine where docker swarm is initilised is called as MAanger
The remianing machines that take the work load are called as Workers.



Setup of Docker Swarm
=======================
1 Create few AWS instances and name as Manager,Worker1 etc

2 Install docker in all of them

3 Change the hostname
  vim /etc/hostname
  Remove the content and replace it with Manager (or) Worker1 (or) Worker2

4 To initilise the swarm manager
  a) Connect to Manager AWS instance uisng git bash
  b) docker swarm init 
     This command will create a docker swarm and it will genrate a token id
     as output,We should this token id in the Worker machine and then they will
     join swarm as workers
  c) Connect to Workers and execute the token id of 4-b step


=============================================================================
Note: Each machine used in swarm is called as node and the collection
of all these nodes is called as Swarm cluster.

Ports used by swarm
-------------------------------
TCP port 2376 for secure Docker client communication. This port is required for Docker Machine to work. Docker Machine is used to orchestrate Docker hosts.

TCP port 2377. This port is used for communication between the nodes of a Docker Swarm or cluster. It only needs to be opened on manager nodes.

TCP and UDP port 7946 for communication among nodes (container network discovery).
UDP port 4789 for overlay network traffic (container ingress networking).


==============================================================================
LoadBalancing:
-------------------
UseCase-1
Create nginx with 5 replicas in docker swarm cluster
docker service create --name webserver -p 8989:80 --replicas 5 nginx

To see on which node these replicas are running
docker service ps webserver

To access nginx from the level of browser
public_ip_of_manager/Worker1/Worker2:8989


============================================================================
UseCase-2
Create mysql with 3 replicas
docker service create --replicas 3 --name db 
                          -e MYSQL_ROOT_PASSWORD=intelliqit mysql:5

To check where these replicas are running
docker service ps db

To delete the mysql db service
docker service rm db

To see the list of services available
docker service ls
=========================================================================


Scalling
=============
UseCase 1
Create tomcat with 3 replicas and increase it to 8 
later scale down to 2

1 Create tomcat with 3 replicas
  docker service create  --name appserver -p 9999:8080 --replicas 3 tomcat

2 To check if 3 replicas of tomcat are running
  docker service ps appserver

3 To scale the replicas count from 3 to 8
  docker service scale appserver=8

4 Check if 8 replicas of tomcat are running
  docker service ps appserver

5 To scale the replicas count to 2
  docker service scale appserver=2

6 Check if 2 replicas are now running
  docker service ps appserver


=====================================================================
Day 16
====================================================================
==========================================================================
Rolling updates
=====================
Create redis:3 with 5 replicas and update it to redis:4
later roll back to redis:3

1 Create redis:3 with 5 replicas
  docker service create --name myredis --replicas 5  redis:3

2 Check if 5 replicas of redis:3 are running
  docker service ps myredis

3 Perform a rolling update from redis:3 to redis:4
  docker service update --image redis:4 myredis

4 Check if 5 replicas of redis:3 are shut down and redis:4 are running
  docker service ps myredis

5 Perform a roll back from redis:4 to redis:3
  docker service update --rollback myredis

6 Check if redis:4 is shutdown and redis:3 is running
  docker service ps myredis


=========================================================================
1 To remove a node from swarm via Manager
  docker node update --availability drain node_name 
  Eg: For Worker1 to leave the swarm
  docker node update --availability drain Worker1

2 To make Worker1 rejoin docker swarm
  docker node update --availability active Worker1

3 Workers can also leave swarm
  a) Connect to Worker2 using git bash
     docker swarm leave
  b) On Manager check the status of nodes
     docker node ls
     It will show worker2 as "Down"
  c) To remove this Worker2 from the cluster
     docker node rm Worker2

4 Manager cam leave swarm
  docker swarm leave --force

5 To generate the token id to a machine to join swarm as worker
  docker swarm join-token worker

6 To generate the token id to a machine to join swarm as manager
  docker swarm join-token manager

7 To promote Worker1 as manager
  docker node promote Worker1

8 To demote a Worker1 from manager to worker
  docker node demote Worker1




===================================================================
Day 17
======================================================================
FailOver Scenarios of Workers
================================
Create httpd with 6 replicas and delete one replica running on the manager
Check if all 6 replicas are still running

Drain Worker1 from the docker swarm and check if all 6 replicas are running
on Manager and Worker2,make Worker1 rejoin the swarm

Make Worker2 leave the swarm and check if all the 6 replicas are
running on Manager and Worker1

1 Create httpd with 6 replicas
  docker service create  --name webserver -p 9090:80 --replicas 6 httpd

2 Check the replicas running on Manager
  docker service ps webserver | grep Manager

3 Check the container id
  docker container ls

4 Delete a replica
  docker rm -f container_id_from_step3

5 Check if all 6 replicas are running
  docker service ps webserver

6 Drain Worker1 from the swarm
  docker node update --availability drain Worker1

7 Check if all 6 replicas are still running on Manager and Worker2
  docker service ps webserver

8 Make Worker1 rejoin the swarm
  docker node update --availability active Worker1

9 Make Worker2 leave the swarm
  Connect to Worker2 using git bash
  docker swarm leave
  Connect to Manager
  
10 Check if all 6 replicas are still running
   docker service ps webserver


============================================================================
======================================================================
FailOver Scenarios of Managers
====================================
If a worker instance crashses all the replicas running on that
worker will be moved to the Manager or the other workers.
If the Manager itself crashes the swarm becomes headless 
ie we cannot perfrom container orchestration activites in this
swamr cluster

To avoid this we should maintain multiple managers
Manager nodes have the status as Leader or Reachable

If one manager node goes down other manager becomes the Leader
Quorum is resonsible for doing this activity and if uses a RAFT
algorithm for handling the failovers of managers.Quorum also 
is responsible for mainting the min number of manager

Min count of manager required for docker swarm should be always
more than half of the total count of Managers

Total Manager Count  -    Min Manager Required
      1              -           1
      2              -           2
      3              -           2
      4              -           3
      5              -           3
      6              -           4
      7              -           4
==============================================================================
Day 18
================================================================================
==============================================================================
Overlay network
==================
This is the deafult network used by docker swarm
and it perfroms network load balancing
ie even if donot have a replica running on a specific node
still we will be able to access that replica service via that node

UseCase
=============
Create 2 custom overlay networks intelliq1 intelliq2
Create htttpd as a service in swarm on the intelliq1 network
Create tomcat as a service in swarm on the default overlay (ingres) 
network and later perform a rolling network update to intelliq2 network

1 Create 2 overlay networks
  docker network create --driver overlay intelliq1
  docker network create --driver overlay intelliq2

2 Check if 2 new networks are create
  docker network ls

3 Start httpd with 5 replicas on intelliq1 network
  docker service create --name webserver -p 8888:80 --replicas 5
                                           --network intelliq1 httpd


4 Check if httpd is running on intelliq1 network
  docker service inspect webserver
  This command generates the output in JSON file format 
  To get the above output in simple text format
  docker service inspect webserver  --pretty

5 Start tomcat with 5 replcias on the defult ingres network
  docker service create --name appserver -p 9090:8080 --replicas 5 tomcat

6 Perfrom a rolling network update to intelliq2 network
  docker service update --network-add intelliq2 appserver

7 Check if tomcat in now running on intelliq2 network
  docker service inspect appserver  --pretty

Note: To remove a service from a  network
  docker service update --network-rm network_name service_name



================================================================================
Docker Stack
====================
This is used for creating a multi container architecture using
docker compose and deploy it in the swarm cluster

docker compose + swarm = docker stack
docker compose + kubernetes = kompose

1 To see the list of stacks
  docker stack ls

2 To create a stack
  docker stack deploy -c stack_filename/docker_compose_file  stack_name

3 To see the list of nodes where the stack services are running
  docker stack ps stack_name

4 To see the list of services in a stack
  docker stack service stack_name

5 To delete a stack
  docker stack rm stack_name







============================================================================
Create a docker stack file for wordpress and mysql
1 vim stack1.yml
---
version: '3'

services:
 mydb:
  image: mysql:5
  environment:
   MYSQL_ROOT_PASSWORD: intelliq

 wordpress:
  image: wordpress
  ports:
   - 8080:80
  deploy:
   replicas: 3
...

2 To deploy this stack service
  docker stack deploy -c stack1.yml wordpress

3 To see where the  stack replicas are running
  docker stack ps wordpress

4 To remove the entire stack
  docker stack rm wordpress


Create a stack file where 2 replicas of jenkins
3 replicas of tomcat as qaserver and 4 replicas of tomcat
as prodserver,
jenkins replicas should run only on manager
tomcat qaserver replicas only on worker1
tomcat prodserver replicas only on worker2

vim stack2.yml
services:
 jenkins:
  image: jenkins
  ports:
   - 5050:8080
  deploy:
   replicas: 1
   placement:
    constraints:
     - node.hostname == Manager

 qaserver:
  image: tomcat
  ports:
   - 6060:8080
  deploy:
   replicas: 2
   placement:
    constraints:
     - node.hostname == Worker1

 prodserver:
  image: tomcat
  ports:
   - 7070:8080
  deploy:
   replicas: 3
   placement:
    constraints:
     - node.hostname == Worker2
    

To deploy the services in swarm
docker stack deploy -c stack2.yml ci-cd

To check if all the serivces are deployed accoring to constraints
docker stack ps ci-cd

To delete the stack
docker stack rm ci-cd



============================================================================
Day 19
============================================================================



UseCase
===============
Create a docker stack file to setup the selenium testing environment
and also put an upper limit on the h/w allocation

1 vim stack3.yml
---
version: '3'

services:
 hub:
  image: selenium/hub
  ports:
   - 4444:4444
  deploy:
   replicas: 1
   resources:
    limits:
     cpus: "0.1"
     memory: "200M"

 chrome:
  image: selenium/node-chrome-debug
  ports:
   - 5901:5900
  deploy:
   replicas: 2
   resources:
    limits:
     cpus: "0.01"
     memory: "50M"

 firefox:
  image: selenium/node-firefox-debug
  ports:
   - 5902:5900
  deploy:
   replicas: 2
   resources:
    limits:
     cpus: "0.01"
     memory: "100M"

2 To deploy the the services from the above stack file
  docker stack deploy -c stack3.yml selenium


====================================================================

=====================================================================


Docker Secrets
==================
This is  a feature of docker swarm using which we can pass encrypted
data to replicas running in swarm cluster
These secrets are creatred on the host machine and they can be accessed
from the replicas but the content cannot be modified in
the replicas

1 To create a secret and pass some data into it
  echo "Hello Intelliq" | docker secret create mysecret -

2 Create an aline:redis with 5 replicas and make it access the secret data
  docker service create --name myredis --replicas 5 --secret mysecret redis

3 Capture the container id
  docker container ls

4 Check if the secret data is available in the container
  docker exec -it container_id_from_step4  cat /run/secrets/mysecret

==========================================================================
UseCase
--------------
Create 3 secrets for postgres user,password and db
and pass them to the stack file

1 Create secrets
  echo "intelliqit" | docker secret create pg_password -
  echo "myuser" | docker secret create pg_user -
  echo "mydb" | docker secret create pg_db -

2 Check if the secrets are created
  docker secret ls

3 Create the docker stack file to work on these secrets
  vim stack4.yml
---
version: '3.1'
services:
  db:
    image: postgres
    environment:
      POSTGRES_PASSWORD_FILE: /run/secrets/pg_password
      POSTGRES_USER_FILE: /run/secrets/pg_user
      POSTGRES_DB_FILE: /run/secrets/pg_db
    secrets:
     - pg_password
     - pg_user
     - pg_db

  adminer:
    image: adminer
    restart: always
    ports:
      - 8080:8080
    deploy:
     replicas: 2

secrets:
    pg_password:
     external: true
    pg_user:
     external: true
    pg_db:
     external: true

...

To deploy the stack file
docker stack deploy -c stack4.yml

==========================================================================
Day 20
==========================================================================
================================================================================
Kubernetes
======================

Menions: This is an individual node used in kubernetes
Combination of these minions is called as Kubernetes cluster

Master is the main machine which triggers the container orchestraion
It distributes the work load to the Slaves

Slaves are the nodes that accept the work load from the master
and handle activites load balancing,autoscalling,high availability etc

kubeadm: This is an application that is responible for creating the 
Master node and it also stores info about the salves

kubeapi: This is an application that runs on the salves and it it
accepts the instructions from kubeadm and executes them on the slaves

kubectl: This is an application that triggers the kubernetes commands

Kubernetes uses various of types of Object

1 Pod: This is a layer of abstraction on top of a container.This is the samallest
  object that kubernetes can work on.In the Pod we have a container.
  The advantage of using a Pod is that kubectl commands will work on the Pod and the 
  Pod communicates these instructions to the container.In this way we can use the
  same  kubectl irresepective of which technology containers are in the Pod.


2 Service: This is used for port mapping and network load balancing

3 NameSpace: This is used for creating partitions in the cluster.Pods running
 in a namespace cannot communicate with other pods running in other namespace

4 Secrets: This is used for passing encrypted data to the Pods

5 ReplicationController: This is used for managing multiple replicas of PODs
and also perfroming saclling 

6 ReplicaSet: This is similar to replicationcontroller but it is more advanced
where features like selector can be implemented

7 Deployment: This used for perfroming all activites that a Replicaset can do
  it can also handle rolling update

8 StatefulSet: This is used to maintain consistency in read write operations
  when working on databases.



========================================================================
Setup of Kubernetes
===============================
Free
===========
1 http://katakoda.com
(or)
2 http://playwithk8s.com

Paid
==============
1 Signup for a Google cloud account
2 Click on Menu icon on top right corner--->Click on Kubernetes Engine-->Clusters
3 Click on Create cluster--->Click on Create=
==============================================================================

Day 21
==============================================================================

UseCase 1
Create an nginx pod in Kubernetes cluster and later
delete it

kubectl run --image nginx webserver 

To see the list if pods
kubectl get pods

To see the list if pods along with their ip address and node where they are running
kubectl get pods -o wide

To see detailed info about the pod
kubectl describe pods pod_name
Eg:  kubectl describe pods webserver

To delete the pod
kubectl delete pods webserver

=============================================================================
UseCase
Create a mysql pod and also pass the necessary environment varibles
kubectl run --image mysql:5 db --env MYSQL_ROOT_PASSWORD=intelliqit

To see the list of pods
kubectl get pods

To delete the pods
kubectl delete pods db

========================================================================
UseCase
Create a deployment with a tomcat pod
kubectl create deployment tomcatdeployment --image tomcat
This will create deployment,within which a replica set will be created
and in the replicaset it will create Pod and in the pod we will
have a tomcat container

To see all the objects in the cluster
kubectl get all

To delete the deployment
kublect delete deployment tomcatdeployment

============================================================================
Kubernetes Definition file
=================================
Kubernetes performs container orchestration uisng certain definition
file.These files are created using yml and they have 4 top level
fields

apiVersion:
kind:
metadata:
spec:

apiVersion: Every kubernetes object uses a specific Kubernetes code
library that is called apiVersion.Only once this code library is imported
we can start working on specific objects

kind: This represents the type of Kubernetes object that we want to us
      eg: Pod,Replicaset,Service etc

metadata: Here we give a name to the Kubernetes object and also some
          labels.These labels can be used later for performing group
          activites

spec: This is where we store info about the exact docker image,container name
      environment varibales,port mapping etc


Kind              apiVersion
=================================
Pod               v1
Service           v1
NameSpace         v1
Secrets           v1
ReplicationController v1
ReplicaSet        apps/v1
Deployment        apps/v1

UseCase-1
Create a pod definition file to start an nginx in a pod 
name the pod as nginx-pod,name the container as appserver

vim pod-defintion1.yml

---
apiVersion: v1
kind: Pod
metadata:
 name: nginx-pod
 labels:
  author: intellqit
  type: proxy
spec:
 containers:
  - name: appserver
    image: nginx
...

To create a pod from the above file
kubectl create -f pod-defintion1.yml

To see the list of pods
kubectl get pods

To see the pods along with the ipaddress and name of the slave where it is running
kubectl get pods -o wide

============================================================================


To delete the pods created from the above file
kubectl delete -f pod-definition1.yml


Create a pod defintion file to start a postgres container
Name of the container should be mydb,pass the necssary environment
variables,this container should run in a pod called postgres-pod
and give the labels as author=intelliqit and type=database


vim pod-definition2.yml
---
apiVersion: v1
kind: Pod
metadata:
 name: postgres-pod
 labels:
  author: intelliqit
  type: database
spec:
 containers:
  - name: mydb
    image: postgres
    env:
     - name: POSTGRES_PASSWORD
       value: myintelliqit
     - name: POSTGRES_USER
       value: myuser
     - name: POSTGRES_DB
       value: mydb
...

To create pods from the above defintion file
kubectl create -f pod-defintion2.yml

To delete the pods
kubectl delete -f pod-definition2.yml


============================================================================
Create a pod defintion file to start a jenkins container in a pod
called jenkins-pod,also perform port mapping to access the jenkins
from a browser

vim pod-definition3.yml
---
apiVersion: v1
kind: Pod
metadata:
 name: jenkins-pod
 labels:
  author: intelliqit
  ci: cd
spec:
 containers:
  - name: myjenkins
    image: jenkins
    ports:
     - containerPort: 8080
       hostPort: 8080
...

To create pods from the above file
kubectl create -f pod-defintion3.yml

To see the list of pods along with nodes where they are running
kubectl get nodes -o wide

To get the external ip of the node
kubectl get node -o wide

To access then jenkins from browser
external_ip_of_slavenode:8080

=======================================================================
Day 22
=======================================================================
========================================================================
ReplicationController
=======================
This is a high level Kubernets object that can be used for handling 
multiple replicas of a Pod.Here we can perfrom Load Balancing
and Scalling

ReplicationController uses keys like "replicas,template" etc in the "spec" section
In the template section we can give metadata related to the pod and also use
another spec section where we can give containers information

Create a replication controller for creating 3 replicas of httpd
vim repilication-controller.yml
---
apiVersion: v1
kind: ReplicationController
metadata:
 name: httpd-rc
 labels:
  author: intelliqit
spec:
 replicas: 3
 template:
  metadata:
   name: httpd-pod
   labels:
    author: intelliqit
  spec:
   containers:
    - name: myhttpd
      image: httpd
      ports:
       - containerPort: 80
         hostPort: 8080
...

To create the httpd replicas from the above file
kubectl create -f replication-controller.yml

To check if 3 pods are running an on whcih slaves they are running
kubectl get pods -o wide

To delete the replicas
kubectl delete -f replication-controller.yml



ReplicaSet
===================
This is also similar to ReplicationController but it is more
advanced and it can also handle load balancing and scalling
It has an additional field in spec section called as "selector"
This selector uses a child element "matchLabels" where the
it will search for Pod based on a specific label name and try to add
them to the cluster

Create a replicaset file to start 4 tomcat replicas  and then perform scalling
vim replica-set.yml
---
apiVersion: apps/v1
kind: ReplicaSet
metadata:
 name: tomcat-rs
 labels:
  type: webserver
  author: intelliqit
spec:
 replicas: 4
 selector:
  matchLabels:
   type: webserver
   
 template:
  metadata:
   name: tomcat-pod
   labels:
    type: webserver
  spec:
   containers:
    - name: mywebserver
      image: tomcat
      ports:
       - containerPort: 8080
         hostPort: 9090

To create the pods from the above file
kubectl create -f replica-set.yml

Scalling can be done in 2 ways
a) Update the file and later scale it

b) Scale from the coomand prompt withbout updating the defintion file

a) Update the file and later scale it
  Open the replicas-set.yml file and increase the replicas count from 4 to 6
  kubectl replace -f replicas-set.yml
  Check if 6 pods of tomcat are running
  kubectl get pods

b) Scale from the coomand prompt withbout updating the defintion file
   kubectl scale --replicas=2 -f replica-set.yml
================================================================

Deployment
================

This is also a high level Kubernetes object which can be used for
scalling and load balancing and it can also perfrom rolling update

Create a deployment file to run nginx:1.7.9 with 3 replicas
Later perform a rolling update to nginx:1.9.1

vim deployment1.yml
---
apiVersion: apps/v1
kind: Deployment
metadata:
 name: nginx-deployment
 labels:
  author: intelliqit
  type: proxyserver
spec:
 replicas: 3
 selector:
  matchLabels:
   type: proxyserver
 template:
  metadata:
   name: nginx-pod
   labels:
    type: proxyserver
  spec:
   containers:
    - name: nginx
      image: nginx:1.7.9
      ports:
       - containerPort: 80
         hostPort: 8888
 
To create the deployment from the above file
kubectl create -f deployment.yml

To check if the deployment is running
kubectl get deployment

To see if all 3 pod of nginx are running
kubectl get pod

Check the version of nginx
kubectl describe pods nginx-deployment | less       (nginx:1.7.9)

Perform a rolling update to nginx:1.9.1
kubectl --record deployment.apps/nginx-deployment set image                           deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1

To check if the update the has happened
kubectl describe pods nginx-deployment | less      (nginx:1.9.1)


==============================================================================
Kompose
================
This is used to implement docker compose to create a multi
container architecture in Kubernetes

Implementing docker compose can be done using Kompose
docker compose + docker swarm = docker stack
docker compose + Kubernetes = Kompose

Setup
===========
1 Download Kompose
  curl -L https://github.com/kubernetes/kompose/releases/download/v1.18.0/kompose-linux-amd64 -o kompose

2 Give execute permissions
  chmod +x kompose

3 Move it to PATH
  sudo mv ./kompose /usr/local/bin/kompose

4 To check if the installion is successfull
  kompose version

Digital Ocean URL
========================
https://www.digitalocean.com/community/tutorials/how-to-migrate-a-docker-compose-workflow-to-kubernetes

========================================================================
Day 23
==========================================================================
Namespace in kubernetes
==========================
Namespaces are used to create partitions in the Kubernetes cluster
Pods runnign in different namespaces cannot communicate with
each other

To create Namespaces
===========
vim namespace.yml
---
apiVersion: v1
  kind: Namespace
  metadata:
    name: test-ns
...

kubectl apply -f namespace.yaml 

To see the list of namespace
================================
kubectl get namespace

Create a pod on that namespace
===================================
vim pod-definition4.yml

---
apiVersion: v1
kind: Pod
metadata:
 name: jdk-pod
 namespace: test-ns
 labels:
  author: intelliqit
spec:
 containers:
  - name: java
    image: openjdk:12
...

To see list of pods in a namespace
======================================
kubectl get pods -n test-ns

To delete a namespace
===========================
kubectl delete namespace test-ns


============================================================================
Volumes
==================
---
apiVersion: v1
kind: Pod
metadata:
 name: redis-pod
 labels:
  author: intelliqit
spec:
 containers:
  - name: redis
    image: redis
    volumeMounts:
     - name: redis-volume
       mountPath: /data/redis
 volumes:
  - name: redis-volume
    emptyDir: {}

Create a pod from the above file
kubectl create -f volumes.yml

To check if the volume is mounted
kubectl exec -it redis-pod -- bash

Go to the redis folder and create some files
cd redis
cat > file
Store some data in this file

To kill the redis pod install procps
apt-get update
apt-get install -y procps

Identify the process id of redis
ps aux
kill 1

Check if the redis-pod is recreated
kubectl get pods
We will see the restart count changes for this pod

If we go into this pods interactive terminal
kubectl exec -it redis-pod -- bash

We will see the data but not the s/w's (procps) we installed
cd redis
ls

ps  This will not work

==============================================================
============================================================
Service Object
=====================

This is used for network load balancing and port mapping
It uses 3 ports
1 target port:  Pod or container port
2 port:   Service port
3 hostPort:  Host machines port to make it accessable from external network

Service objects are classified into 3 types
1 clusterIP: This is the default type of service object used in
  Kubernetes and it is used when we want the Pods in the cluster to
  communicate with each other and not with extrnal networks

2 nodePort: This is used if we want to access the pods from an extrnal
  network and it also performs network load balancing ie even if a pod
  is running on a specific salve we can access it from other slave in
  the cluster

3 LoadBalancer: This is similar to Nodeport and it is used for external 
  connectivity of a Pod and also network load balancing and it also assigns
  a public ip for all the slave combined together


==============================================================================
Day 24
===============================================================================
Create a service defintion file of type of NodePort
and open these ports on a pod with 
labels-author: intelliqit type: frontend

vim service1.yml
---
apiVersion: v1
kind: Service
metadata:
 name: httpd-service
 labels:
  author: intelliqit
spec:
 type: NodePort
 ports:
  - targetPort: 80
    port: 80
    nodePort: 30008
 selector:
  type: frontend
  author: intelliqit
...

vim pod-defintion5.yml

---
apiVersion: v1
kind: Pod
metadata:
 name: httpd-pod
 labels:
  author: intelliqit
  type: frontend
spec:
 containers:
  - name: appserver
    image: httpd
...                                                                                   
To create a pod
kubectl create -f pod-definition5.yml

To create a service 
kubectl create -f service.yml

To access the application from browser
Give public if any node: 3008

------------------------------------------------------------

Create a service object of type Load balancer
and open the port on a ghot pod

vim service2.yml

---
apiVersion: v1
kind: Service
metadata:
 name: ghost-service
 labels:
  author: intelliqit
spec:
 type: LoadBalancer
 ports:
  - targetPort: 2368
    port: 2368
 selector:
  author: intelliqit
  type: cms
...

To create a pod defintion file
vim pod-defintion6.yml

---
apiVersion: v1
kind: Pod
metadata:
 name: ghost-pod
 labels:
  author: intelliqit
  type: cms
spec:
 containers:
  - name: ghost
    image: ghost
...

To create a pod
kubectl apply -f pod-defintion6.yml

To create a service
kubectl apply -f service2.yml

We will see a single ip assigned for all slaves combined
Click on Ingress and Services

===================================================================

Create a service object of type clusterip and 
assign to a postgres pod

vim service3.yml

---
apiVersion: v1
kind: Service
metadata:
 name: postgres-service
 labels:
  author: intelliqit
spec:
 ports:
  - targetPort: 5432
    port: 5432
 selector:
  type: db
  author: intelliqit
...

vim pod-defintion2.yml

---
apiVersion: v1
kind: Pod
metadata:
 name: postgres-pod
 labels:
  type: db
  author: intelliqit
spec:
 containers:
  - name: mydb
    image: postgres
    env:
     - name: POSTGRES_PASSWORD
       value: intelliqt
     - name: POSTGRES_USER
       value: myuser
     - name: POSTGRES_DB
       value: mydb
...

To create pod
kubectl apply -f postgres-pod.yml

To create a service
kubectl apply -f service3.yml

===================================================================
Day 25
===================================================================   
=========================================================================
Kubernetes Project
========================
This is a python based application which is used for accepting a vote
(voting app).This application accepts the vote and passes it to a
temporary db created using redis.From here the data is passed to a
worker application created using .net which anlysises the data and
stores them permananatly in a database created using postgres
From here the results can be seen on an application that is created 
using nodejs and this is called as resulta-app

To do this we will create 5 pod definition files
and 4 service files,2 services of type cluster ip for redis and postgres 
databases 2 services of type loadbalancer for python voting app and 
nodejs result app



vim voting-app-pod.yml

---
apiVersion: v1
kind: Pod
metadata:
  name: voting-app-pod
  labels:
    name: voting-app-pod
    app: demo-voting-app
spec:
  containers:
    - name: voting-app
      image: dockersamples/examplevotingapp_vote
      ports:
        - containerPort: 80
...


vim result-app-pod.yml
---
apiVersion: v1
kind: Pod
metadata:
  name: result-app-pod
  labels:
    name: result-app-pod
    app: demo-voting-app
spec:
  containers:
    - name: result-app
      image: dockersamples/examplevotingapp_result
      ports:
        - containerPort: 80
...


vim worker-app-pod.yml

---
apiVersion: v1
kind: Pod
metadata:
  name: worker-app-pod
  labels:
    name: worker-app-pod
    app: demo-voting-app
spec:
  containers:
    - name: worker-app
      image: dockersamples/examplevotingapp_worker
...


vim redis-pod.yml
---
apiVersion: v1
kind: Pod
metadata:
  name: redis-pod
  labels:
    name: redis-pod
    app: demo-voting-app
spec:
  containers:
   - name: redis
     image: redis
     ports:
       - containerPort: 6379
...

vim postgres-pod.yml

---
apiVersion: v1
kind: Pod
metadata:
  name: postgres-pod
  labels:
    name: postgres-pod
    app: demo-voting-app
spec:
  containers:
    - name: postgres
      image: postgres:9.4
      ports:
        - containerPort: 5432
...


============================================================================
Service Defintion file
===============================
vim redis-service.yml
---
apiVersion: v1
kind: Service
metadata:
  name: redis-service
  labels:
    name: redis-service
    app: demo-voting-app
spec:
  ports:
    - port: 6379
      targetPort: 6379
  selector:
    name: redis-pod
    app: demo-voting-app
...

vim pod-service.yml
---
apiVersion: v1
kind: Service
metadata:
  name: postgres-service
  labels:
    name: postgres-service
    app: demo-voting-app
spec:
  ports:
    - port: 5432
      targetPort: 5432
  selector:
    name: postgres-pod
    app: demo-voting-app
...

Note: Since "type" is not specified in the "spec" section they  will
be created as clusterIP




vim voting-app-service.yml
---
apiVersion: v1
kind: Service
metadata:
  name: voting-app-service
  labels:
    name: voting-app-service
    app: demo-voting-app
spec:
  type: LoadBalancer
  ports:
    - port: 80
      targetPort: 80
  selector:
    name: voting-app-pod
    app: demo-voting-app
...

vim result-app-service.yml
---
apiVersion: v1
kind: Service
metadata:
  name: result-app-service
  labels:
    name: result-app-service
    app: demo-voting-app
spec:
  type: LoadBalancer
  ports:
    - port: 80
      targetPort: 80
  selector:
    name: result-app-pod
    app: demo-voting-app
...


The above 2 service objects are created as LoadBalancer type ie
they can perfrom network load balancing where we can access the pod
from any slave and also a single public ip will be assigned for all
the salves



==========================================================================
Day 26
==========================================================================
Setup of Kubernetes Manually
================================
Install, start and enable docker service

yum install -y -q yum-utils device-mapper-persistent-data lvm2 > /dev/null 2>&1
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo > /dev/null 2>&1
yum install -y -q docker-ce >/dev/null 2>&1


systemctl start docker
systemctl enable docker

=====================================================================================
Disable SELINUX

setenforce 0
sed -i --follow-symlinks 's/^SELINUX=enforcing/SELINUX=disabled/' /etc/sysconfig/selinux

============================================================================================
Disable SWAP

sed -i '/swap/d' /etc/fstab
swapoff -a

===========================================================================================
Update sysctl settings for Kubernetes networking

cat >>/etc/sysctl.d/kubernetes.conf<<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sysctl --system

============================================================================================
Add Kubernetes to yum repository

cat >>/etc/yum.repos.d/kubernetes.repo<<EOF
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

======================================================================================
Install Kubernetes
yum install -y kubeadm kubelet kubectl

==================================================================================
Enable and start Kubernetes service

systemctl start kubelet
systemctl enable kubelet
=====================================================================================
Repeat the above steps on Master and slaves
=======================================================================================

On Master=============
===========
Initilise the Kubernetes cluster
-----------------------------------------

kubeadm init --apiserver-advertise-address=ip_of_master --pod-network-cidr=192.168.0.0/16

=========================================================================================

To be able to use kubectl command to connect and interact with the cluster, 
the user needs kube config file.

mkdir /home/centos/.kube
cp /etc/kubernetes/admin.conf /home/centos/.kube/config
chown -R centos:centos /home/centos/.kube

========================================================================================
Deploy calico network
kubectl create -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml

========================================================================================
For slaves to join the cluster
kubeadm token create --print-join-command

======================================================================================
Check the pods of kube-system  are running

kubectl get pods -n kube-system

==============================================================================


To open certain ports on the Google cloud Kubernetes engine
-------------------------------------------------------------------
gcloud compute firewall-rules create rule-name --allow tcp:8080                                                                                 
                                                                                                                                                                                                                                                                                    